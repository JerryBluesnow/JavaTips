

- [内存连续分配管理方式](https://www.jianshu.com/p/f9c2cd85e2f6?utm_campaign=maleskine&utm_content=note&utm_medium=seo_notes&utm_source=recommendation)

- [操作系统---内存管理](https://www.cnblogs.com/roccoshi/p/13052164.html)


- [STL内存管理器的分配策略](https://blog.csdn.net/adcxf/article/details/6437880)
```
大多数情况下，STL默认的allocator就已经足够了。这个allocator是一个由两级分配器构成的内存管理器，当申请的内存大小大于128byte时，就启动第一级分配器通过malloc直接向系统的堆空间分配，如果申请的内存大小小于128byte时，就启动第二级分配器，从一个预先分配好的内存池中取一块内存交付给用户，这个内存池由16个不同大小（8的倍数，8~128byte）的空闲列表组成，allocator会根据申请内存的大小（将这个大小round up成8的倍数）从对应的空闲块列表取表头块给用户。

这种做法有两个优点：

1）小对象的快速分配。小对象是从内存池分配的，这个内存池是系统调用一次malloc分配一块足够大的区域给程序备用，当内存池耗尽时再向系统申请一块新的区域，整个过程类似于批发和零售，起先是由allocator向总经商批发一定量的货物，然后零售给用户，与每次都总经商要一个货物再零售给用户的过程相比，显然是快捷了。当然，这里的一个问题时，内存池会带来一些内存的浪费，比如当只需分配一个小对象时，为了这个小对象可能要申请一大块的内存池，但这个浪费还是值得的，况且这种情况在实际应用中也并不多见。

2）避免了内存碎片的生成。程序中的小对象的分配极易造成内存碎片，给操作系统的内存管理带来了很大压力，系统中碎片的增多不但会影响内存分配的速度，而且会极大地降低内存的利用率。以内存池组织小对象的内存，从系统的角度看，只是一大块内存池，看不到小对象内存的分配和释放。

STL第一级配置器 / STL 第二级配置器
SGI设计了双层级配置器，第一级配置器直接使用malloc()和free()，第二级配置器则视情况采用不同的策略：当配置区块超过128bytes时，视之为“足够大”，便调用第一级配置器；当配置区小于128bytes时，视之为“过小”，为了降低额外负担，便采用复杂的memory pool 整理方式，而不再求助于第一级配置器。整个设计究竟只开放第一级配置器，取决于_USE_MALLOC是否被定义：
```

- [Go的内存分配器/内存池](https://www.cntofu.com/book/3/zh/06.1.md)

```
Go中为每个系统线程分配一个本地的MCache(前面介绍的结构体M中的MCache域)，少量的地址分配就直接从MCache中分配，并且定期做垃圾回收，将线程的MCache中的空闲内存返回给全局控制堆。小于32K为小对象，大对象直接从全局控制堆上以页(4k)为单位进行分配，也就是说大对象总是以页对齐的。一个页可以存入一些相同大小的小对象，小对象从本地内存链表中分配，大对象从中心内存堆中分配。
```

- [如何设计内存池？- 知乎](https://www.zhihu.com/question/25527491?sort=created)

- [C++ 应用程序性能优化，第 6 章：内存池](https://www.ibm.com/developerworks/cn/linux/l-cn-ppp/index6.html)

- [内存池原理大揭秘](https://segmentfault.com/a/1190000017007208?utm_source=sf-related)

- [STL六大组件之——分配器（内存分配，好深奥的东西）](https://blog.csdn.net/weixin_30337251/article/details/96730740?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-2.control&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-2.control)

## 内存池的目的

```
1. 如果应用程序频繁地在堆上分配和释放内存，则会导致性能的损失。并且会使系统中出现大量的内存碎片，降低内存的利用率。
避免内存碎片和内存碎块

2. 速度远比 malloc/free 快，因为减少了系统调用的次数，特别是频繁申请/释放内存块的情况
3. 避免了频繁申请/释放内存之后，系统的大量内存碎片
4. 节省空间

```

### Variable-size Allocation / Fixed-size Allocation
- 单线程内存池 - 性能更高
- 多线程内存池 - 适用范围更广
- 固定内存池
- 可变内存池
- 伙伴算法
- 覆盖算法
- 紧凑技术

- [内存的分配与管理](https://www.cnblogs.com/Hhhighway/p/12805564.html)

动态重定位寄存器

首次适应算法

最佳适应算法

循环首次适应算法

最坏适应算法

```
首次适应算法：空闲分区以地址递增的次序链接。分配内存时顺序查找，找到大小能满足要求的第一个空闲分区。
优点：最简单，最快，有利于大作业分配。
缺点：会使得内存的低地址部分出现很多小的空闲分区，而每次分配查找时，都要经过这些分区，因此也增加了查找的开销。
最佳适应算法：空闲分区按容量递增形成分区链，找到第一个能满足要求的空闲分区。
缺点：性能通常很差，因为每次最佳的分配会留下很小的难以利用的内存块，它会产生最多的外部碎片。
循环首次适应算法：由首次适应算法演变而成。不同之处是分配内存时从上次查找结束的位置开始继续查找。
缺点：邻近适应算法试图解决查找开销这个问题，但实际上，它常常会导致在内存的末尾分配空间（因为在一遍扫描中，内存前面部分使用后再释放时，不会参与分配)，分裂成小碎片。它通常比首次适应算法的结果要差。
最坏适应算法：空闲分区以容量递减的次序链接。找到第一个能满足要求的空闲分区，也就是挑选出最大的分区。
选择最大的可用块，这看起来最不容易产生碎片，但是却把最大的连续内存划分开，会很快导致没有可用的大的内存块，因此性能也非常差。
```

## 虚拟内存地址与物理内存地址
为了简单便捷，现代操作系统在汇编程序（或机器语言）层面，处理内存地址时，都是使用虚拟内存地址。这样每个进程可以自己独享一片2N字节的内存，其中N是机器位数。例如在64位CPU和64位OS下，每个进程的虚拟地址空间为2*64 Byte。

虚拟地址的作用主要是简化程序的编写及方便操作系统对进程间内存的隔离管理，由于在机器语言层面都是采用虚拟地址，操作系统会将虚拟内存和实际的物理内存进行映射，CPU芯片上叫做存储器管理单元(Memory Management Unit，MMU)的专用硬件，利用存放在主存中的查询表来动态翻译虚拟地址，才能实现对真实内存数据的操作。

## 